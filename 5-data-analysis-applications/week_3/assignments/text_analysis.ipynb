{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SMSSpamCollection.txt', 'r', encoding=\"utf8\") as f:\n",
    "    sms = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"spam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_texts = []\n",
    "sms_labels = []\n",
    "\n",
    "for line in sms:\n",
    "    if line[0] == 'h': \n",
    "        sms_texts.append(line[4:])\n",
    "        sms_labels.append(0)\n",
    "        \n",
    "    else: \n",
    "        sms_texts.append(line[5:])\n",
    "        sms_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(sms_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vectorizer', CountVectorizer()), ('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.9333\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(pipeline, sms_texts, sms_labels, scoring = 'f1', cv=10).mean()\n",
    "\n",
    "print(f\"Cross validation score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"answer_1.txt\", 'w') as f:\n",
    "    f.write(str(round(score, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_test = [\"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\",\n",
    "            \"FreeMsg: Txt: claim your reward of 3 hours talk time\",\n",
    "            \"Have you visited the last lecture on physics?\",\n",
    "            \"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\",\n",
    "            \"Only 99$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipeline.fit(sms_texts, sms_labels).predict(sms_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"answer_2.txt\", 'w') as f:\n",
    "    f.write(\" \".join(list(map(str, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_3 = []\n",
    "\n",
    "ngram_ranges = [(2,2), (3,3), (1,3)]\n",
    "\n",
    "for ngram_range in ngram_ranges:\n",
    "    pipeline = Pipeline([('vectorizer', CountVectorizer(ngram_range=ngram_range)), ('classifier', LogisticRegression())])\n",
    "    score = cross_val_score(pipeline, sms_texts, sms_labels, scoring='f1').mean()\n",
    "    ans_3.append(str(round(score, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"answer_3.txt\", 'w') as f:\n",
    "    f.write(\" \".join(ans_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_4 = []\n",
    "\n",
    "ngram_ranges = [(2,2), (3,3), (1,3)]\n",
    "\n",
    "for ngram_range in ngram_ranges:\n",
    "    X = CountVectorizer(ngram_range=ngram_range).fit_transform(sms_texts)\n",
    "    score = cross_val_score(MultinomialNB(), X, sms_labels, scoring='f1').mean()\n",
    "    ans_4.append(str(round(score, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"answer_4.txt\", 'w') as f:\n",
    "    f.write(\" \".join(ans_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.8785\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('vectorizer', TfidfVectorizer()), ('classifier', LogisticRegression())])\n",
    "score = cross_val_score(pipeline, sms_texts, sms_labels, scoring = 'f1', cv=10).mean()\n",
    "\n",
    "print(f\"Cross validation score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer_5.txt', 'w') as f:\n",
    "    ans5 = str(-1)\n",
    "    f.write(ans5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
